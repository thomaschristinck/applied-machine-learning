{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) IMDB Dataset\n",
    "------------\n",
    "The IMDB dataset consists of 15000 reviews in training set, 10000 reviews in validation set, and 25000 reviews in test set. This is a 2 class problem with class 1 being positive sentiment and class 0 being negative sentiment.\n",
    "\n",
    "Here, we format such that each line in the train/val/test file is a data point with word occurances encoded by their respective index.\n",
    "\n",
    "This takes a couple minutes to run, because we save the dataset as a\n",
    "nb_example x 10000 feature matrix, where 10000 is the number of words \n",
    "in the vocabulary, and nb_example is the number of examples in the set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset split\n",
    "train_dir = os.path.join(os.getcwd(), 'hwk3_datasets/IMDB-train.txt')\n",
    "val_dir = os.path.join(os.getcwd(), 'hwk3_datasets/IMDB-valid.txt')\n",
    "test_dir = os.path.join(os.getcwd(), 'hwk3_datasets/IMDB-test.txt')\n",
    "\n",
    "train_data = pd.read_csv(train_dir, sep='\\t', names=['review', 'score'], header = None)\n",
    "val_data = pd.read_csv(val_dir, sep='\\t', names=['review', 'score'], header = None)\n",
    "test_data = pd.read_csv(test_dir, sep='\\t', names=['review', 'score'], header = None)\n",
    "\n",
    "# Now, remove punctuation and capital letters - we want to keep only word\n",
    "# characteres (letters and numbers) so [^\\w\\s]\n",
    "# Note we also want to get rid of '<br />', which is kind of a special case\n",
    "train_data['review'] = train_data['review'].str.replace('<br />', '')\n",
    "train_data['review'] = train_data['review'].str.replace(r'[^\\w\\s]+', '')\n",
    "train_data['review'] = train_data['review'].str.lower()\n",
    "val_data['review'] = val_data['review'].str.replace('<br />', '')\n",
    "val_data['review'] = val_data['review'].str.replace(r'[^\\w\\s]+', '')\n",
    "val_data['review'] = val_data['review'].str.lower()\n",
    "test_data['review'] = test_data['review'].str.replace('<br />', '')\n",
    "test_data['review'] = test_data['review'].str.replace(r'[^\\w\\s]+', '')\n",
    "test_data['review'] = test_data['review'].str.lower()\n",
    "\n",
    "\n",
    "# Will take the 10000 most frequent words\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "vectorizer.fit(train_data['review'])\n",
    "train_vectors = vectorizer.transform(train_data['review'])\n",
    "test_vectors = vectorizer.transform(test_data['review'])\n",
    "val_vectors = vectorizer.transform(val_data['review'])\n",
    "words = vectorizer.get_feature_names()\n",
    "train_matrix = np.asarray(train_vectors)\n",
    "frequency_vector = np.asarray(train_vectors.sum(axis=0)).reshape(10000,)\n",
    "frequency_list = frequency_vector.tolist()\n",
    "\n",
    "index_list = range(10000)\n",
    "frequency_list, index_list, words = zip(*sorted(zip(frequency_list, index_list, words), reverse=True))\n",
    "\n",
    "# Get the vocabulary. \n",
    "vocabulary = vectorizer.vocabulary_\n",
    "\n",
    "with open(\"imdb-vocab.txt\",'w') as vocab_file:\n",
    "    for i in range(10000):\n",
    "        vocab_file.write(\"{0:<12}\\t{1:>5}\\t{2:>8}\\n\".format(words[i], index_list[i], frequency_list[i] ))\n",
    "\n",
    "# Build train file\n",
    "nb_examples_train = 15000\n",
    "nb_examples_val = 10000\n",
    "nb_examples_test = 25000\n",
    "nb_features = 10000\n",
    "# Set up BBoW with 1 if example has word in index, 0 if not\n",
    "BBOW_trainx = np.zeros((nb_examples_train, nb_features))\n",
    "BBOW_trainy = np.zeros((nb_examples_train,))\n",
    "# Set up FBoW with word_count/total_count if example has word in index, 0 if not\n",
    "FBOW_trainx = np.zeros((nb_examples_train, nb_features))\n",
    "FBOW_trainy = np.zeros((nb_examples_train,))\n",
    "example = 0\n",
    "with open(\"imdb-train.txt\",'w') as train_file:\n",
    "    for review in train_data['review']:\n",
    "        occurances = 0\n",
    "        words = review.split()\n",
    "        paragraph = \"\"\n",
    "        for word in words:\n",
    "            index = vocabulary.get(word)\n",
    "            if index is not None:\n",
    "                paragraph += str(index)+ \" \"\n",
    "                BBOW_trainx[example, index] = 1\n",
    "                FBOW_trainx[example, index] += 1\n",
    "                occurances += 1\n",
    "        BBOW_trainy[example] = train_data['score'][example]\n",
    "        FBOW_trainy[example] = train_data['score'][example]\n",
    "        train_file.write(\"{}\\t{}\\n\".format(paragraph, train_data['score'][example]))\n",
    "        if occurances != 0:\n",
    "            FBOW_trainx[example] /= occurances\n",
    "        example += 1\n",
    "np.savetxt(\"inputs/imdb-train-bbow_x.txt\", BBOW_trainx, delimiter=\",\", fmt='%d')\n",
    "np.savetxt(\"inputs/imdb-train-bbow_y.txt\", BBOW_trainy, delimiter=\",\", fmt='%d')\n",
    "np.savetxt(\"inputs/imdb-train-fbow_x.txt\", FBOW_trainx, delimiter=\",\", fmt='%1.5f')\n",
    "np.savetxt(\"inputs/imdb-train-fbow_y.txt\", FBOW_trainy, delimiter=\",\", fmt='%d')\n",
    "\n",
    "# Build validation file\n",
    "BBOW_valx = np.zeros((nb_examples_val, nb_features))\n",
    "BBOW_valy = np.zeros((nb_examples_val,))\n",
    "FBOW_valx = np.zeros((nb_examples_val, nb_features))\n",
    "FBOW_valy = np.zeros((nb_examples_val,))\n",
    "example = 0\n",
    "with open(\"imdb-val.txt\",'w') as val_file:\n",
    "    for review in val_data['review']:\n",
    "        occurances = 0\n",
    "        words = review.split()\n",
    "        paragraph = \"\"\n",
    "        for word in words:\n",
    "            index = vocabulary.get(word)           \n",
    "            if index is not None:\n",
    "                paragraph += str(index)+ \" \"\n",
    "                BBOW_valx[example, index] = 1\n",
    "                FBOW_valx[example, index] += 1\n",
    "                occurances += 1\n",
    "        BBOW_valy[example] = val_data['score'][example]\n",
    "        FBOW_valy[example] = train_data['score'][example]\n",
    "        val_file.write(\"{}\\t{}\\n\".format(paragraph, val_data['score'][example]))\n",
    "        if occurances != 0:\n",
    "            FBOW_valx[example] /= occurances\n",
    "        example += 1\n",
    "np.savetxt(\"inputs/imdb-val-bbow_x.txt\", BBOW_valx, delimiter=\",\", fmt='%d')\n",
    "np.savetxt(\"inputs/imdb-val-bbow_y.txt\", BBOW_valy, delimiter=\",\", fmt='%d')\n",
    "np.savetxt(\"inputs/imdb-val-fbow_x.txt\", FBOW_valx, delimiter=\",\", fmt='%1.5f')\n",
    "np.savetxt(\"inputs/imdb-val-fbow_y.txt\", FBOW_valy, delimiter=\",\", fmt='%d')\n",
    "\n",
    "# Build test file\n",
    "BBOW_testx = np.zeros((nb_examples_test, nb_features))\n",
    "BBOW_testy = np.zeros((nb_examples_test,))\n",
    "FBOW_testx = np.zeros((nb_examples_test, nb_features))\n",
    "FBOW_testy = np.zeros((nb_examples_test,))\n",
    "example = 0\n",
    "with open(\"imdb-test.txt\",'w') as test_file:\n",
    "    for review in test_data['review']:\n",
    "        occurances = 0\n",
    "        words = review.split()\n",
    "        paragraph = \"\"\n",
    "        for word in words:\n",
    "            index = vocabulary.get(word)           \n",
    "            if index is not None:\n",
    "                paragraph += str(index)+ \" \"\n",
    "                BBOW_testx[example, index] = 1\n",
    "                FBOW_testx[example, index] += 1\n",
    "                occurances += 1\n",
    "    BBOW_testy[example] = test_data['score'][example]\n",
    "    FBOW_testy[example] = test_data['score'][example]\n",
    "    test_file.write(\"{}\\t{}\\n\".format(paragraph, test_data['score'][example]))\n",
    "    if occurances != 0:\n",
    "        FBOW_testx[example] /= occurances\n",
    "    example += 1\n",
    "np.savetxt(\"inputs/imdb-test-bbow_x.txt\", BBOW_testx, delimiter=\",\", fmt='%d')\n",
    "np.savetxt(\"inputs/imdb-test-bbow_y.txt\", BBOW_testy, delimiter=\",\", fmt='%d')\n",
    "np.savetxt(\"inputs/imdb-test-fbow_x.txt\", FBOW_testx, delimiter=\",\", fmt='%1.5f')\n",
    "np.savetxt(\"inputs/imdb-test-fbow_y.txt\", FBOW_testy, delimiter=\",\", fmt='%d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Yelp Dataset\n",
    "------------\n",
    "The Yelp dataset consists of 7000 reviews in the training set, 1000 reviews in the validation set, and 2000 reviews in the test set. This is a 5 class problem where each review is classified into one of the five ratings with rating-5 being the best score and rating-1 being the worst score.\n",
    "\n",
    "Here, we format such that each line in the train/val/test file is a data point with word occurances encoded by their respective index.\n",
    "\n",
    "As for the IMDB dataset, this takes a couple minutes to run, because we save the dataset as a\n",
    "nb_example x 10000 feature matrix, where 10000 is the number of words \n",
    "in the vocabulary, and nb_example is the number of examples in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset split\n",
    "train_dir = os.path.join(os.getcwd(), 'hwk3_datasets/yelp-train.txt')\n",
    "val_dir = os.path.join(os.getcwd(), 'hwk3_datasets/yelp-valid.txt')\n",
    "test_dir = os.path.join(os.getcwd(), 'hwk3_datasets/yelp-test.txt')\n",
    "\n",
    "train_data = pd.read_csv(train_dir, sep='\\t', names=['review', 'score'], header = None)\n",
    "val_data = pd.read_csv(val_dir, sep='\\t', names=['review', 'score'], header = None)\n",
    "test_data = pd.read_csv(test_dir, sep='\\t', names=['review', 'score'], header = None)\n",
    "\n",
    "# Now, remove punctuation and capital letters - we want to keep only word\n",
    "# characteres (letters and numbers) so [^\\w\\s]\n",
    "train_data['review'] = train_data['review'].str.replace(r'[^\\w\\s]+', '')\n",
    "train_data['review'] = train_data['review'].str.lower()\n",
    "val_data['review'] = val_data['review'].str.replace(r'[^\\w\\s]+', '')\n",
    "val_data['review'] = val_data['review'].str.lower()\n",
    "test_data['review'] = test_data['review'].str.replace(r'[^\\w\\s]+', '')\n",
    "test_data['review'] = test_data['review'].str.lower()\n",
    "\n",
    "# Will take the 10000 most frequent words\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "vectorizer.fit(train_data['review'])\n",
    "train_vectors = vectorizer.transform(train_data['review'])\n",
    "test_vectors = vectorizer.transform(test_data['review'])\n",
    "val_vectors = vectorizer.transform(val_data['review'])\n",
    "words = vectorizer.get_feature_names()\n",
    "train_matrix = np.asarray(train_vectors)\n",
    "frequency_vector = np.asarray(train_vectors.sum(axis=0)).reshape(10000,)\n",
    "frequency_list = frequency_vector.tolist()\n",
    "\n",
    "index_list = range(10000)\n",
    "frequency_list, index_list, words = zip(*sorted(zip(frequency_list, index_list, words), reverse=True))\n",
    "\n",
    "# Get the vocabulary. \n",
    "vocabulary = vectorizer.vocabulary_\n",
    "\n",
    "with open(\"yelp-vocab.txt\",'w') as vocab_file:\n",
    "    for i in range(10000):\n",
    "        vocab_file.write(\"{0:<12}\\t{1:>5}\\t{2:>8}\\n\".format(words[i], index_list[i], frequency_list[i] ))\n",
    "\n",
    "# Build train file\n",
    "nb_examples_train = 7000\n",
    "nb_examples_val = 1000\n",
    "nb_examples_test = 2000\n",
    "nb_features = 10000\n",
    "example = 0\n",
    "# Set up BBoW with 1 if example has word in index, 0 if not\n",
    "BBOW_trainx = np.zeros((nb_examples_train, nb_features))\n",
    "BBOW_trainy = np.zeros((nb_examples_train,))\n",
    "# Set up FBoW with word_count/total_count if example has word in index, 0 if not\n",
    "FBOW_trainx = np.zeros((nb_examples_train, nb_features))\n",
    "FBOW_trainy = np.zeros((nb_examples_train,))\n",
    "with open(\"yelp-train.txt\",'w') as train_file:\n",
    "    for review in train_data['review']:\n",
    "        occurances = 0\n",
    "        words = review.split()\n",
    "        paragraph = \"\"\n",
    "        for word in words:\n",
    "            index = vocabulary.get(word)\n",
    "            if index is not None:\n",
    "                paragraph += str(index)+ \" \"\n",
    "                BBOW_trainx[example, index] = 1\n",
    "                FBOW_trainx[example, index] += 1\n",
    "                occurances += 1\n",
    "        BBOW_trainy[example] = train_data['score'][example]\n",
    "        FBOW_trainy[example] = train_data['score'][example]\n",
    "        train_file.write(\"{}\\t{}\\n\".format(paragraph, train_data['score'][example]))\n",
    "        if occurances != 0:\n",
    "            FBOW_trainx[example] /= occurances\n",
    "        example += 1\n",
    "np.savetxt(\"inputs/yelp-train-bbow_x.txt\", BBOW_trainx, delimiter=\",\", fmt='%d')\n",
    "np.savetxt(\"inputs/yelp-train-bbow_y.txt\", BBOW_trainy, delimiter=\",\", fmt='%d')\n",
    "np.savetxt(\"inputs/yelp-train-fbow_x.txt\", FBOW_trainx, delimiter=\",\", fmt='%1.5f')\n",
    "np.savetxt(\"inputs/yelp-train-fbow_y.txt\", FBOW_trainy, delimiter=\",\", fmt='%1.5f')\n",
    "\n",
    "# Build validation file\n",
    "BBOW_valx = np.zeros((nb_examples_val, nb_features))\n",
    "BBOW_valy = np.zeros((nb_examples_val,))\n",
    "FBOW_valx = np.zeros((nb_examples_val, nb_features))\n",
    "FBOW_valy = np.zeros((nb_examples_val,))\n",
    "example = 0\n",
    "with open(\"yelp-val.txt\",'w') as val_file:\n",
    "    for review in val_data['review']:\n",
    "        occurances = 0\n",
    "        words = review.split()\n",
    "        paragraph = \"\"\n",
    "        for word in words:\n",
    "            index = vocabulary.get(word)           \n",
    "            if index is not None:\n",
    "                paragraph += str(index)+ \" \"\n",
    "                BBOW_valx[example, index] = 1\n",
    "                FBOW_valx[example, index] += 1\n",
    "                occurances += 1\n",
    "        BBOW_valy[example] = val_data['score'][example]\n",
    "        FBOW_valy[example] = val_data['score'][example]\n",
    "        val_file.write(\"{}\\t{}\\n\".format(paragraph, val_data['score'][example]))\n",
    "        if occurances != 0:\n",
    "            FBOW_valx[example] /= occurances\n",
    "        example += 1\n",
    "np.savetxt(\"inputs/yelp-val-bbow_x.txt\", BBOW_valx, delimiter=\",\", fmt='%d')\n",
    "np.savetxt(\"inputs/yelp-val-bbow_y.txt\", BBOW_valy, delimiter=\",\", fmt='%d')\n",
    "np.savetxt(\"inputs/yelp-val-fbow_x.txt\", FBOW_valx, delimiter=\",\", fmt='%1.5f')\n",
    "np.savetxt(\"inputs/yelp-val-fbow_y.txt\", FBOW_valy, delimiter=\",\", fmt='%1.5f')\n",
    "\n",
    "# Build test file\n",
    "BBOW_testx = np.zeros((nb_examples_test, nb_features))\n",
    "BBOW_testy = np.zeros((nb_examples_test,))\n",
    "FBOW_testx = np.zeros((nb_examples_test, nb_features))\n",
    "FBOW_testy = np.zeros((nb_examples_test,))\n",
    "example = 0\n",
    "with open(\"yelp-test.txt\",'w') as test_file:\n",
    "    for review in test_data['review']:\n",
    "        occurances = 0\n",
    "        words = review.split()\n",
    "        paragraph = \"\"\n",
    "        for word in words:\n",
    "            index = vocabulary.get(word)           \n",
    "            if index is not None:\n",
    "                paragraph += str(index)+ \" \"\n",
    "                BBOW_testx[example, index] = 1\n",
    "                FBOW_testx[example, index] += 1\n",
    "                occurances += 1\n",
    "        BBOW_testy[example] = test_data['score'][example]\n",
    "        FBOW_testy[example] = test_data['score'][example]\n",
    "        test_file.write(\"{}\\t{}\\n\".format(paragraph, test_data['score'][example]))\n",
    "        if occurances != 0:\n",
    "            FBOW_testx[example] /= occurances\n",
    "        example += 1\n",
    "np.savetxt(\"inputs/yelp-test-bbow_x.txt\", BBOW_testx, delimiter=\",\", fmt='%d')\n",
    "np.savetxt(\"inputs/yelp-test-bbow_y.txt\", BBOW_testy, delimiter=\",\", fmt='%d')\n",
    "np.savetxt(\"inputs/yelp-test-fbow_x.txt\", FBOW_testx, delimiter=\",\", fmt='%1.5f')\n",
    "np.savetxt(\"inputs/yelp-test-fbow_y.txt\", FBOW_testy, delimiter=\",\", fmt='%1.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
