{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Gaussian Discriminant Analysis\n",
    "---------------------------------------\n",
    "We have two classes from (1). Now, we use a GDA model where we assume that the class conditional densities are Gaussian and that the two classes share the same covariance matrix. We estimate the parameters using the maximum likelihood approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(training_set):\n",
    "    \n",
    "    # Populate list X with data\n",
    "    data = list(csv.reader(open(training_set)))\n",
    "    X = []\n",
    "    for index in range(len(data)):\n",
    "        X.append(data[index])\n",
    "    # Convert lists to numpy float arrays\n",
    "    training_set = np.asarray(X)\n",
    "    training_set = training_set.astype(np.float)\n",
    "    \n",
    "    # Get matrix of training examples. We want to find u0, u1, cov (s0, s1), pclass_0, pclass_1\n",
    "    total = len(training_set)\n",
    "    u_0 = 0\n",
    "    u_1 = 0\n",
    "    s_0 = 0\n",
    "    s_1 = 0\n",
    "    count_0 = 0\n",
    "    count_1 = 0\n",
    "    \n",
    "    # Loop through once to get class counts and sum (for u_0, u_1)\n",
    "    for row in training_set:\n",
    "        # Check class label\n",
    "        if row[-1] == -1:\n",
    "            u_0 += row[:-1]\n",
    "            count_0 += 1\n",
    "        elif row[-1] == 1:\n",
    "            u_1 += row[:-1]\n",
    "            count_1 += 1\n",
    "        else:\n",
    "            print(\"Made a mistake with dataset creation!\")\n",
    "     \n",
    "    # Get averages across the row\n",
    "    u_0 /= count_0\n",
    "    u_1 /= count_1\n",
    "    \n",
    "    # Posterior probabilities (follow Bernoulli(pi), where pi = N_0/N)\n",
    "    pclass_0 = count_0 / total\n",
    "    pclass_1 = count_1 / total\n",
    "    \n",
    "    # Loop through again to get (x(n) - u)(x(n) - u) ^T (for s_0, s_1)\n",
    "    for row in training_set:\n",
    "        # Check class label\n",
    "        if row[-1] == -1:\n",
    "            x_0 = row[:-1] - u_0\n",
    "            x_0 = x_0[:, np.newaxis]\n",
    "            s_0 += np.dot(x_0, x_0.T)\n",
    "        \n",
    "        elif row[-1] == 1:\n",
    "            x_1 = row[:-1] - u_1\n",
    "            x_1 = x_1[:, np.newaxis]\n",
    "            s_1 += np.dot(x_1, x_1.T)\n",
    "        else:\n",
    "            print(\"Made a mistake with dataset creation!\")\n",
    "        \n",
    "    # Get s_0, s_1\n",
    "    s_0 /= count_0\n",
    "    s_1 /= count_1\n",
    "\n",
    "    # Now we can find the covariance matrix\n",
    "    cov = (pclass_0 * s_0) + (pclass_1 * s_1)\n",
    "\n",
    "    # Finally, get weights w0, w1\n",
    "    cov_inverse = np.linalg.inv(cov)\n",
    "    w_1 = np.dot(cov_inverse, (u_0 - u_1))\n",
    "    w_0 = -0.5 * np.dot(u_0.T, np.dot(cov_inverse, u_0)) + 0.5 * np.dot(u_1.T, np.dot(cov_inverse, u_1)) \\\n",
    "    + np.log(pclass_0/pclass_1)\n",
    "    print(\"%%%%%%%%  Weights   %%%%%%%\\n\")\n",
    "    print(\"w_1 : \\n\", w_1)\n",
    "    print(\"w_0 : \\n\", w_0)\n",
    "    \n",
    "    weight_dir = os.path.join(os.getcwd(), 'Assignment2_260601793_2_1_coefficients.txt')\n",
    "    text_coefs = np.append(w_0, w_1)\n",
    "    np.savetxt(weight_dir, text_coefs, delimiter=\",\", header='w_0 (the bias term) first, then w_1 (the feature weights)')\n",
    "        \n",
    "    return w_1, w_0\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pclass_0(w_1, w_0, x):\n",
    "    # Returns probability of class 0 (negative class) given x\n",
    "    a = np.dot(w_1, x) + w_0   \n",
    "    return sigmoid(a) \n",
    "\n",
    "def get_pclass_1(w_1, w_0, x):\n",
    "    # Returns probability of class 1 (positive class) given x\n",
    "    return 1 - pclass_0(w_1, w_0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    # Generic sigmoid function (apply as sigmoid(w^T x + w0))\n",
    "    sig = 1/ (1 + np.exp(-x))\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_set, w_1, w_0):\n",
    "    # Given the coeficients we learned, use test set to evaluate the accuracy, precision,\n",
    "    # recall, and F-measure performance of the model.\n",
    "\n",
    "    # Populate list X with data\n",
    "    data = list(csv.reader(open(test_set)))\n",
    "    X = []\n",
    "    for index in range(len(data)):\n",
    "        X.append(data[index])\n",
    "    \n",
    "    # Convert lists to numpy float arrays\n",
    "    test_set = np.asarray(X)\n",
    "    test_set = test_set.astype(np.float)\n",
    "    \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    total = 0\n",
    "\n",
    "    # Go through test set examples. Check label. Get class probability and if it is less than\n",
    "    # 0.5, choose the negative class \n",
    "    for row in test_set:\n",
    "        target_class = row[-1]\n",
    "        pclass_0 = get_pclass_0(w_1, w_0, row[:-1])\n",
    "        total +=1\n",
    "        if pclass_0 < 0.5:\n",
    "            choice = 1\n",
    "            if target_class == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else :\n",
    "            choice = 0\n",
    "            if target_class == -1:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "    \n",
    "    acc = (tn + tp)/ total\n",
    "    prec = tp / (tp + fp) \n",
    "    recall = tp / (tp + fn)\n",
    "    fmeasure = 2 * prec * recall / (prec + recall)\n",
    "\n",
    "    print(\"\\n%%%%%%%%%% Performance Metrics %%%%%%%%%%%%%\\n\")\n",
    "    print(\"Accuracy: {}\".format(acc))\n",
    "    print(\"Precision: {}\".format(prec))\n",
    "    print(\"Recall: {}\".format(recall))\n",
    "    print(\"F-Measure: {}\".format(fmeasure))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%  Weights   %%%%%%%\n",
      "\n",
      "w_1 : \n",
      " [ 14.61824043  -8.54453874  -5.45640546  -2.78454392  -9.72679861\n",
      "  -4.52021572  16.5667912  -24.47268517 -29.16183147   9.45524633\n",
      " -13.36125264 -12.35934761  15.60255283  12.82041171  -5.82533067\n",
      "  13.43813039  29.30757966  -6.9410348   -0.12493205  -5.28734351]\n",
      "w_0 : \n",
      " 27.681970714115067\n",
      "\n",
      "%%%%%%%%%% Performance Metrics %%%%%%%%%%%%%\n",
      "\n",
      "Accuracy: 0.95375\n",
      "Precision: 0.9437652811735942\n",
      "Recall: 0.965\n",
      "F-Measure: 0.9542645241038319\n"
     ]
    }
   ],
   "source": [
    "training_set = 'DS1_train_set.csv'\n",
    "test_set = 'DS1_test_set.csv'\n",
    "w_1, w_0 = learn(training_set)\n",
    "evaluate(test_set, w_1, w_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
